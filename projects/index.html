<!DOCTYPE html>
<html lang="en-us">
<head>
  <link rel="preload" href="/lib/font-awesome/webfonts/fa-brands-400.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="preload" href="/lib/font-awesome/webfonts/fa-regular-400.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="preload" href="/lib/font-awesome/webfonts/fa-solid-900.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="preload" href="/lib/JetBrainsMono/web/woff2/JetBrainsMono-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title> Projects | Weixuan Wang</title>
  <link rel = 'canonical' href = 'https://weixuan-wang123.github.io/projects/'>
  <meta name="description" content="I am a second-year PhD student in NLP, School of Informatics, University of Edinburgh advised by [Prof. Alexandra Birch](https://sites.google.com/view/alexandra-birch/) and [Dr. Barry Haddow](https://homepages.inf.ed.ac.uk/bhaddow/). 

My research interests lie in the field of Natural Language Processing. I broadly work on **Multilingual LLM**, **SFT**, **Inference-time Intervention**, **Language Agents**, and **Interpretability**. My recent work focuses on data-efficient methods for training LLMs, particularly techniques that fine-tune LLMs using heterogeneous data sources. I am currently exploring ways to improve LLM performance in multilingual settings, including through SFT, RL, inference-time interventions, RAG, and related approaches.

Previously, I completed MS (by Research) from Dalian University of Technology where I concentrate on the research on Neural Machine Translation.
I have worked as an AI researcher for 3&#43; years at IT Innovation and Research Center (IIRC), and AI Application Research Center (AARC), **Huawei Technologies Co., Ltd.**, resulting in a collective research experience of 8 years across academia and big-tech.">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="robots" content="all,follow">
  <meta name="googlebot" content="index,follow,snippet,archive">
  <meta property="og:url" content="https://weixuan-wang123.github.io/projects/">
  <meta property="og:site_name" content="Weixuan Wang">
  <meta property="og:title" content="Projects">
  <meta property="og:description" content="Large Commercial Neural Machine Translation January 2023 to September 2023 Responsibility: developing commercial NMT with LLM, designing the multilingual training data proportion Achievements: Performance based on PanGu LLM on par with existing end-to-end NMT model in 10&#43; languages End-to-end Simultaneous Speech Translation July 2022 to May 2023 Responsibility: designing and evaluating the first end-to-end simultaneous translation system for Huawei meeting Achievements: The end-to-end simultaneous translation system has lower latency and higher performance than the cascaded translation system Cascade Simultaneous Speech Translation June 2021 to July 2022 Responsibility: designing and developing cascade simultaneous translation system for Huawei meeting Achievements: SST end-to-end BLEU scores (EN&lt;-&gt; ZH) on par with existing commercial systems; The service successfully supported 110 &#43; online conference sessions and 30 &#43; onsite SST translation service for 2021/2022 Huawei STW event Knowledge-enhanced NMT September 2020 to May 2021 Responsibility: designing, implementing and evaluating knowledge-enhance NMT algorithms based on topic modelling and homographic representation learning (HDR) Achievements: BLEU enhancement on the vanllia transformer Topic-enhanced model (&#43;1.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">

  <meta name="twitter:card" content="summary"><meta name="twitter:title" content="Projects">
<meta name="twitter:description" content="Large Commercial Neural Machine Translation January 2023 to September 2023 Responsibility: developing commercial NMT with LLM, designing the multilingual training data proportion Achievements: Performance based on PanGu LLM on par with existing end-to-end NMT model in 10&#43; languages End-to-end Simultaneous Speech Translation July 2022 to May 2023 Responsibility: designing and evaluating the first end-to-end simultaneous translation system for Huawei meeting Achievements: The end-to-end simultaneous translation system has lower latency and higher performance than the cascaded translation system Cascade Simultaneous Speech Translation June 2021 to July 2022 Responsibility: designing and developing cascade simultaneous translation system for Huawei meeting Achievements: SST end-to-end BLEU scores (EN&lt;-&gt; ZH) on par with existing commercial systems; The service successfully supported 110 &#43; online conference sessions and 30 &#43; onsite SST translation service for 2021/2022 Huawei STW event Knowledge-enhanced NMT September 2020 to May 2021 Responsibility: designing, implementing and evaluating knowledge-enhance NMT algorithms based on topic modelling and homographic representation learning (HDR) Achievements: BLEU enhancement on the vanllia transformer Topic-enhanced model (&#43;1.">

  
  
    
  
  
  <link rel="stylesheet" href="https://weixuan-wang123.github.io/css/styles.832f844a18081a513455a3bf961dde17b5478d975436c578c9c3cfda4f77c0d89a107619cbe6687e0bf8b145f6590245d268ef2fc6bbd5c89685defaaf00ead0.css" integrity="sha512-gy&#43;EShgIGlE0VaO/lh3eF7VHjZdUNsV4ycPP2k93wNiaEHYZy&#43;Zofgv4sUX2WQJF0mjvL8a71ciWhd76rwDq0A=="> 

  
  
  
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  

  
<link rel="icon" type="image/png" href="https://weixuan-wang123.github.io/images/favicon.ico" />

  
  
  
  
</head>

<body class="max-width mx-auto px3 ltr">
  <div class="content index py4">

    <header id="header">
  <a href="https://weixuan-wang123.github.io/">
  
    
    <div id="logo" style="background-image: url(https://weixuan-wang123.github.io/images/photo.jpg)"></div>

  
  <div id="title">
    <h1>Weixuan Wang</h1>
  </div>
  </a>
  <div id="nav">
    <ul>
      <li class="icon">
        <a href="#" aria-label="Menu"><i class="fas fa-bars fa-2x" aria-hidden="true"></i></a>
      </li>
      
        <li><a href="/">Home</a></li>
      
        <li><a href="/cv">CV</a></li>
      
        <li><a href="/publications">Publications</a></li>
      
        <li><a href="/projects">Projects</a></li>
      
    </ul>
  </div>
</header>



    
<article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <div class="content" itemprop="articleBody">
  
    <h3 id="large-commercial-neural-machine-translation">Large Commercial Neural Machine Translation</h3>
<p><font size=2>January 2023 to September 2023 </font></p>
<ul>
<li><strong>Responsibility</strong>: developing commercial NMT with LLM, designing the multilingual training data proportion</li>
<li><strong>Achievements</strong>: Performance based on PanGu LLM on par with existing end-to-end NMT model in 10+ languages</li>
</ul>
<h3 id="end-to-end-simultaneous-speech-translation">End-to-end Simultaneous Speech Translation</h3>
<p><font size=2>July 2022 to May 2023 </font></p>
<ul>
<li><strong>Responsibility</strong>: designing and evaluating the first end-to-end simultaneous translation system for Huawei meeting</li>
<li><strong>Achievements</strong>: The end-to-end simultaneous translation system has lower latency and higher performance than the cascaded translation system</li>
</ul>
<h3 id="cascade-simultaneous-speech-translation">Cascade Simultaneous Speech Translation</h3>
<p><font size=2>June 2021 to July 2022 </font></p>
<ul>
<li><strong>Responsibility</strong>: designing and developing cascade simultaneous translation system for Huawei meeting</li>
<li><strong>Achievements</strong>: SST end-to-end BLEU scores (EN&lt;-&gt; ZH) on par with existing commercial systems; The service successfully supported 110 + online conference sessions and 30 + onsite SST translation service for 2021/2022 Huawei STW event</li>
</ul>
<h3 id="knowledge-enhanced-nmt">Knowledge-enhanced NMT</h3>
<p><font size=2>September 2020 to May 2021 </font></p>
<ul>
<li><strong>Responsibility</strong>: designing, implementing and evaluating knowledge-enhance NMT algorithms based on topic modelling and homographic representation learning (HDR)</li>
<li><strong>Achievements</strong>: BLEU enhancement on the vanllia transformer Topic-enhanced model (+1.57 EN-&gt;DE), HDR (+2.3 in EN-&gt;RU) with algorithm deployed in related Huawei machine translation service; 2 peer-reviewed conference papers</li>
</ul>
<h3 id="domain-specific-nmt">Domain-specific NMT</h3>
<p><font size=2>June 2020 to February 2021 </font></p>
<ul>
<li><strong>Responsibility</strong>: developing ICT domain-specific machine translation model leveraging domain dictionaries</li>
<li><strong>Achievements</strong>: BLEU increase +0.7 on SOTA EN-&gt;ZH working model</li>
</ul>
<h3 id="machine-translation-data-processing-pipeline">Machine Translation Data Processing Pipeline</h3>
<p><font size=2>July 2019 to July 2020 </font></p>
<ul>
<li><strong>Responsibility</strong>: lead developing corpus processing pipeline consisting of corpus cleaning, tokenize, data enhancement, and other functions like visualization</li>
<li><strong>Achievements</strong>: Huawei machine translation data processing pipeline V1.0</li>
</ul>

  
  </div>
</article>


    <footer id="footer">
  <div class="footer-left">
    Copyright  &copy; 2025  Weixuan Wang 
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
        <li><a href="/">Home</a></li>
         
        <li><a href="/cv">CV</a></li>
         
        <li><a href="/publications">Publications</a></li>
         
        <li><a href="/projects">Projects</a></li>
        
      </ul>
    </nav>
  </div>
</footer>


  </div>
</body>

<link rel="stylesheet" href=/lib/font-awesome/css/all.min.css>
<script src=/lib/jquery/jquery.min.js></script>
<script src=/js/main.js></script>
</html>
