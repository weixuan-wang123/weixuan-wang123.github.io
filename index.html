<!doctype html><html lang=en-us dir=ltr data-wc-theme-default=system><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Hugo Blox Builder 0.8.0"><meta name=author content="Weixuan Wang"><meta name=description content="PhD Student"><link rel=alternate hreflang=en-us href=https://weixuan-wang123.github.io/><link rel=stylesheet href=./css/themes/indigo.min.css>
    

  
  
  
  
  
  
  
    
      
        <link rel="stylesheet" href="/css/_entry.e92486b05ece8ab99770a84586bf72c0ff069fb23ec0139f2722f4380420ca32.css" integrity="sha256-6SSGsF7OirmXcKhFhr9ywP8Gn7I&#43;wBOfJyL0OAQgyjI=" crossorigin="anonymous">
      
    
  


  
<link href=./css/custom.min.46de64151e07865019f3973f769177d752dbb34e81483ab7a18c980cb07d6009.css rel=stylesheet><script src=./js/hb-head.min.4f709a77731090398c609176d6a8ca70c152ef89185db97631774ffe9011d746.js integrity="sha256-T3Cad3MQkDmMYJF21qjKcMFS74kYXbl2MXdP/pAR10Y=" crossorigin=anonymous></script><link rel=alternate href=./index.xml type=application/rss+xml title="Weixuan Wang"><link rel=icon type=image/png href=./media/icon_hu_a0e9113daefd3b25.png><link rel=apple-touch-icon type=image/png href=./media/icon_hu_60c23f177be80c9e.png><link rel=canonical href=https://weixuan-wang123.github.io/><meta property="twitter:card" content="summary"><meta property="og:site_name" content="Weixuan Wang"><meta property="og:url" content="https://weixuan-wang123.github.io/"><meta property="og:title" content="Weixuan Wang"><meta property="og:description" content="PhD Student"><meta property="og:image" content="https://weixuan-wang123.github.io/media/icon_hu_e5e9d60a72fc8280.png"><meta property="twitter:image" content="https://weixuan-wang123.github.io/media/icon_hu_e5e9d60a72fc8280.png"><meta property="og:locale" content="en-us"><meta property="og:updated_time" content="2022-10-24T00:00:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"WebSite","url":"https://weixuan-wang123.github.io/"}</script><title>Weixuan Wang</title><style>@font-face{font-family:inter var;font-style:normal;font-weight:100 900;font-display:swap;src:url(/dist/font/Inter.var.woff2)format(woff2)}</style><script defer src=./js/hugo-blox-en.min.e5457af121a1723ecc08c85decf334bb5824911e7b3ad19c11ce5d694ac3ce11.js integrity="sha256-5UV68SGhcj7MCMhd7PM0u1gkkR57OtGcEc5daUrDzhE="></script><link type=text/css rel=stylesheet href=./dist/pagefind/pagefind-ui.be766eb419317a14ec769d216e9779bfe8f3737c80e780f4ba0dafb57a41a482.css integrity="sha256-vnZutBkxehTsdp0hbpd5v+jzc3yA54D0ug2vtXpBpII="><script src=./dist/pagefind/pagefind-ui.87693d7c6f2b3b347ce359d0ede762c033419f0a32b22ce508c335a81d841f1b.js integrity="sha256-h2k9fG8rOzR841nQ7ediwDNBnwoysizlCMM1qB2EHxs="></script><script id=search-config type=application/json>{"baseUrl":"/"}</script><style>html.dark{--pagefind-ui-primary:#eeeeee;--pagefind-ui-text:#eeeeee;--pagefind-ui-background:#152028;--pagefind-ui-border:#152028;--pagefind-ui-tag:#152028}.search-close>svg{height:calc(64px * var(--pagefind-ui-scale));width:calc(64px * var(--pagefind-ui-scale))}</style><script defer src=./js/hb-search.min.4b44970077f9b8dbb07f9abdbfe86060821705a17efd24530e336de452d72890.js integrity="sha256-S0SXAHf5uNuwf5q9v+hgYIIXBaF+/SRTDjNt5FLXKJA=" crossorigin=anonymous></script></head><body class="dark:bg-hb-dark dark:text-white page-wrapper" id=top><div id=page-bg></div><div class="page-header sticky top-0 z-30"><header id=site-header class=header><nav class="navbar px-3 flex justify-start"><div class="order-0 h-full"><a class=navbar-brand href=./ title="Weixuan Wang"></a></div><input id=nav-toggle type=checkbox class=hidden>
<label for=nav-toggle class="order-3 cursor-pointer flex items-center lg:hidden text-dark dark:text-white lg:order-1"><svg id="show-button" class="h-6 fill-current block" viewBox="0 0 20 20"><title>Open Menu</title><path d="M0 3h20v2H0V3zm0 6h20v2H0V9zm0 6h20v2H0V0z"/></svg>
<svg id="hide-button" class="h-6 fill-current hidden" viewBox="0 0 20 20"><title>Close Menu</title><polygon points="11 9 22 9 22 11 11 11 11 22 9 22 9 11 -2 11 -2 9 9 9 9 -2 11 -2" transform="rotate(45 10 10)"/></svg></label><ul id=nav-menu class="navbar-nav order-3 hidden lg:flex w-full pb-6 lg:order-1 lg:w-auto lg:space-x-2 lg:pb-0 xl:space-x-8 justify-start"><li class=nav-item><a class="nav-link active" href=./>Bio</a></li><li class=nav-item><a class=nav-link href=./#papers>Publications</a></li><li class=nav-item><a class=nav-link href=./experience/>Experience</a></li><li class=nav-item><a class=nav-link href=./projects/>Projects</a></li></ul><div class="order-1 ml-auto flex items-center md:order-2 lg:ml-0"><button aria-label="toggle search" class="text-black hover:text-primary inline-block px-3 text-xl dark:text-white" data-search-toggle>
<svg height="16" width="16" viewBox="0 0 512 512" fill="currentColor"><path d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8.0 45.3s-32.8 12.5-45.3.0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9.0 208S93.1.0 208 0 416 93.1 416 208zM208 352a144 144 0 100-288 144 144 0 100 288z"/></svg></button><div class="px-3 text-black hover:text-primary-700 dark:text-white dark:hover:text-primary-300
[&.active]:font-bold [&.active]:text-black/90 dark:[&.active]:text-white"><button class="theme-toggle mt-1" accesskey=t title=appearance>
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="block dark:hidden"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="hidden dark:block"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div></nav></header><div id=search-wrapper class="hidden fixed inset-0 z-50 bg-white dark:bg-gray-900 flex flex-col overflow-hidden"><div class="flex justify-end p-3"><button aria-label=search class="search-close text-black hover:text-primary dark:text-white" data-search-toggle>
<svg fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="size-6"><path stroke-linecap="round" stroke-linejoin="round" d="M6 18 18 6M6 6l12 12"/></svg></button></div><div id=search class="flex-1 overflow-y-auto p-3"></div></div></div><div class=page-body><section id=bio class="relative hbb-section blox-resume-biography-3 hbx-bg-gradient"><div class=home-section-bg></div><div class="resume-biography py-8 px-4 sm:py-12 md:py-16 lg:py-24 xl:py-32 relative overflow-hidden"><div class="max-w-7xl mx-auto"><div class="grid grid-cols-1 md:grid-cols-12 gap-6 md:gap-8 items-start"><div class="md:col-span-4 flex flex-col items-center text-center space-y-6 md:space-y-8"><div class="avatar-wrapper mb-4" style=width:320px;height:320px><img class="avatar rounded-full border-4 border-white shadow-2xl" src=./authors/admin/avatar_hu_9cccbe02490aa690.png alt="Weixuan Wang" width=320 height=320 style=width:320px;height:320px;object-fit:cover></div><div class=space-y-3><h1 class="text-5xl lg:text-6xl font-black text-gray-900 dark:text-white leading-tight">Weixuan Wang</h1><p class="text-2xl font-semibold text-primary-600 dark:text-primary-400">PhD Student</p><p class="text-lg text-gray-700 dark:text-gray-300">University of Edinburgh</p></div><div class="flex flex-wrap justify-center gap-4"><a href=mailto:weixuan.wang@ed.ac.uk aria-label=at-symbol title="E-mail Me" class="w-12 h-12 flex items-center justify-center rounded-full bg-white dark:bg-gray-800 text-gray-600 dark:text-gray-400
shadow-md hover:shadow-xl hover:scale-110 hover:-translate-y-1
transition-all duration-300 border border-gray-200 dark:border-gray-700"><svg class="w-6 h-6" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-width="1.5" d="M16.5 12a4.5 4.5.0 11-9 0 4.5 4.5.0 019 0zm0 0c0 1.657 1.007 3 2.25 3S21 13.657 21 12a9 9 0 10-2.636 6.364M16.5 12V8.25"/></svg>
</a><a href=https://twitter.com/WeixuanWang66 target=_blank rel=noopener aria-label=brands/x class="w-12 h-12 flex items-center justify-center rounded-full bg-white dark:bg-gray-800 text-gray-600 dark:text-gray-400
shadow-md hover:shadow-xl hover:scale-110 hover:-translate-y-1
transition-all duration-300 border border-gray-200 dark:border-gray-700"><svg class="w-6 h-6" viewBox="0 0 512 512"><path fill="currentColor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
</a><a href=https://github.com/weixuan-wang123 target=_blank rel=noopener aria-label=brands/github class="w-12 h-12 flex items-center justify-center rounded-full bg-white dark:bg-gray-800 text-gray-600 dark:text-gray-400
shadow-md hover:shadow-xl hover:scale-110 hover:-translate-y-1
transition-all duration-300 border border-gray-200 dark:border-gray-700"><svg class="w-6 h-6" fill="currentColor" viewBox="3 3 18 18"><path d="M12 3C7.0275 3 3 7.12937 3 12.2276c0 4.0833 2.57625 7.5321 6.15374 8.7548C9.60374 21.0631 9.77249 20.7863 9.77249 20.5441 9.77249 20.3249 9.76125 19.5982 9.76125 18.8254 7.5 19.2522 6.915 18.2602 6.735 17.7412 6.63375 17.4759 6.19499 16.6569 5.8125 16.4378 5.4975 16.2647 5.0475 15.838 5.80124 15.8264 6.51 15.8149 7.01625 16.4954 7.18499 16.7723 7.99499 18.1679 9.28875 17.7758 9.80625 17.5335 9.885 16.9337 10.1212 16.53 10.38 16.2993 8.3775 16.0687 6.285 15.2728 6.285 11.7432c0-1.0035.34875-1.834.92249-2.47994C7.1175 9.03257 6.8025 8.08674 7.2975 6.81794c0 0 .753749999999999-.24223 2.47499.94583.72001-.20762 1.48501-.31143 2.25001-.31143C12.7875 7.45234 13.5525 7.55615 14.2725 7.76377c1.7212-1.19959 2.475-.94583 2.475-.94583C17.2424 8.08674 16.9275 9.03257 16.8375 9.26326 17.4113 9.9092 17.76 10.7281 17.76 11.7432c0 3.5411-2.1037 4.3255-4.1063 4.5561C13.98 16.5877 14.2613 17.1414 14.2613 18.0065 14.2613 19.2407 14.25 20.2326 14.25 20.5441 14.25 20.7863 14.4188 21.0746 14.8688 20.9824 16.6554 20.364 18.2079 19.1866 19.3078 17.6162c1.0999-1.5705 1.6917-3.4551 1.6922-5.3886C21 7.12937 16.9725 3 12 3z"/></svg>
</a><a href=https://www.linkedin.com/in/weixuan-wang-0a2078216/ target=_blank rel=noopener aria-label=brands/linkedin class="w-12 h-12 flex items-center justify-center rounded-full bg-white dark:bg-gray-800 text-gray-600 dark:text-gray-400
shadow-md hover:shadow-xl hover:scale-110 hover:-translate-y-1
transition-all duration-300 border border-gray-200 dark:border-gray-700"><svg class="w-6 h-6" height="1em" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</a><a href="https://scholar.google.com/citations?user=qAduuoUAAAAJ&amp;hl=en" target=_blank rel=noopener aria-label=academicons/google-scholar class="w-12 h-12 flex items-center justify-center rounded-full bg-white dark:bg-gray-800 text-gray-600 dark:text-gray-400
shadow-md hover:shadow-xl hover:scale-110 hover:-translate-y-1
transition-all duration-300 border border-gray-200 dark:border-gray-700"><svg class="w-6 h-6" viewBox="0 0 512 512"><path fill="currentColor" d="M343.759 106.662V79.43L363.524 64h-213.89L20.476 176.274h85.656a82.339 82.339.0 00-.219 6.225c0 20.845 7.22 38.087 21.672 51.861 14.453 13.797 32.252 20.648 53.327 20.648 4.923.0 9.75-.368 14.438-1.024-2.907 6.5-4.374 12.523-4.374 18.142.0 9.875 4.499 20.43 13.467 31.642-39.234 2.67-68.061 9.732-86.437 21.163-10.531 6.5-19 14.704-25.39 24.531-6.391 9.9-9.578 20.515-9.578 31.962.0 9.648 2.062 18.336 6.219 26.062 4.156 7.726 9.578 14.07 16.312 18.984 6.718 4.968 14.469 9.101 23.219 12.469 8.734 3.344 17.406 5.718 26.061 7.062A167.052 167.052.0 00180.555 448c13.469.0 26.953-1.734 40.547-5.187 13.562-3.485 26.28-8.642 38.171-15.493 11.86-6.805 21.515-16.086 28.922-27.718 7.39-11.68 11.094-24.805 11.094-39.336.0-11.016-2.25-21.039-6.75-30.14-4.468-9.073-9.938-16.542-16.452-22.345-6.501-5.813-13-11.155-19.516-15.968-6.5-4.845-12-9.75-16.468-14.813-4.485-5.046-6.735-10.054-6.735-14.984.0-4.921 1.734-9.672 5.216-14.265 3.455-4.61 7.674-9.048 12.61-13.306 4.937-4.25 9.875-8.968 14.796-14.133 4.922-5.147 9.141-11.827 12.61-20.008 3.485-8.18 5.203-17.445 5.203-27.757.0-13.453-2.547-24.46-7.547-33.314-.594-1.022-1.218-1.803-1.875-3.022l56.907-46.672v17.119c-7.393.93-6.624 5.345-6.624 10.635V245.96c0 5.958 4.875 10.834 10.834 10.834h3.989c5.958.0 10.833-4.875 10.833-10.834V117.293c0-5.277.778-9.688-6.561-10.63zm-107.36 222.48c1.14.75 3.704 2.78 7.718 6.038 4.05 3.243 6.797 5.695 8.266 7.414a443.553 443.553.0 016.376 7.547c2.813 3.375 4.718 6.304 5.718 8.734 1 2.477 2.016 5.461 3.047 8.946a38.27 38.27.0 011.485 10.562c0 17.048-6.564 29.68-19.656 37.859-13.125 8.18-28.767 12.274-46.938 12.274-9.187.0-18.203-1.093-27.063-3.196-8.843-2.116-17.311-5.336-25.39-9.601-8.078-4.258-14.577-10.204-19.5-17.797-4.938-7.64-7.407-16.415-7.407-26.25.0-10.32 2.797-19.29 8.422-26.906 5.594-7.625 12.938-13.391 22.032-17.315 9.063-3.946 18.25-6.742 27.562-8.398a157.865 157.865.0 0128.438-2.555c4.47.0 7.936.25 10.405.696.455.219 3.032 2.07 7.735 5.563 4.704 3.462 7.625 5.595 8.75 6.384zm-3.359-100.579c-7.406 8.86-17.734 13.288-30.953 13.288-11.86.0-22.298-4.764-31.266-14.312-9-9.523-15.422-20.328-19.344-32.43-3.937-12.109-5.906-23.984-5.906-35.648.0-13.694 3.596-25.352 10.781-34.976 7.187-9.65 17.5-14.485 30.938-14.485 11.875.0 22.374 5.038 31.437 15.157 9.094 10.085 15.61 21.413 19.517 33.968 3.922 12.54 5.873 24.53 5.873 35.984.0 13.446-3.702 24.61-11.076 33.454z"/></svg></a></div></div><div class=md:col-span-8><div class=mb-12><div class="flex items-center gap-4 mb-8"><div class="flex-shrink-0 w-12 h-12 bg-primary-100 dark:bg-primary-900/50 rounded-full flex items-center justify-center"><svg class="w-6 h-6 text-primary-600 dark:text-primary-400" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M15 9h3.75M15 12h3.75M15 15h3.75M4.5 19.5h15a2.25 2.25.0 002.25-2.25V6.75A2.25 2.25.0 0019.5 4.5h-15A2.25 2.25.0 002.25 6.75v10.5A2.25 2.25.0 004.5 19.5m6-10.125a1.875 1.875.0 11-3.75.0 1.875 1.875.0 013.75.0m1.294 6.336a6.721 6.721.0 01-3.17.789 6.721 6.721.0 01-3.168-.789 3.376 3.376.0 016.338.0"/></svg></div><h2 class="text-xl sm:text-2xl lg:text-3xl font-bold text-gray-900 dark:text-white tracking-tight">About Me</h2></div><div class="prose prose-lg dark:prose-invert text-gray-800 dark:text-gray-200 text-base sm:text-lg leading-relaxed"><div class=bio-text><p>I am a third-year PhD student in NLP, School of Informatics, University of Edinburgh advised by <a href=https://sites.google.com/view/alexandra-birch/ target=_blank rel=noopener>Prof. Alexandra Birch</a> and <a href=https://homepages.inf.ed.ac.uk/bhaddow/ target=_blank rel=noopener>Dr. Barry Haddow</a>.</p><p>My research interests lie in the field of Natural Language Processing. I broadly work on <strong>Multilingual LLM</strong>, <strong>SFT</strong>, <strong>Inference-time Intervention</strong>, <strong>Language Agents</strong>, and <strong>Interpretability</strong>. My recent work focuses on efficient methods for improving LLMs, particularly techniques that fine-tune LLMs using heterogeneous data sources. I am currently exploring ways to improve LLM performance in multilingual settings, including through SFT, RL, inference-time interventions, RAG, and related approaches.</p><p>Previously, I completed MS (by Research) from Dalian University of Technology where I concentrate on the research on Neural Machine Translation.
I have worked as an AI researcher for 3+ years at IT Innovation and Research Center (IIRC), and AI Application Research Center (AARC), <strong>Huawei Technologies Co., Ltd.</strong>, resulting in a collective research experience of 8 years across academia and big-tech.</p></div></div></div><div class=mb-16><a href=uploads/resume.pdf target=_blank class="inline-flex items-center px-8 py-4 bg-gradient-to-r from-primary-600 to-secondary-600 hover:from-primary-700 hover:to-secondary-700 text-white font-bold text-lg rounded-xl shadow-lg hover:shadow-xl hover:scale-105 transition-all duration-300"><svg class="w-5 h-5 mr-3" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M19.5 14.25v-2.625A3.375 3.375.0 0016.125 8.25h-1.5A1.125 1.125.0 0113.5 7.125v-1.5A3.375 3.375.0 0010.125 2.25H8.25m.75 12 3 3m0 0 3-3m-3 3v-6m-1.5-9H5.625c-.621.0-1.125.504-1.125 1.125v17.25c0 .621.504 1.125 1.125 1.125h12.75c.621.0 1.125-.504 1.125-1.125V11.25a9 9 0 00-9-9"/></svg>
Download CV</a></div><div class=mb-16><div class="flex items-center gap-4 mb-8"><div class="flex-shrink-0 w-12 h-12 bg-primary-100 dark:bg-primary-900/50 rounded-full flex items-center justify-center"><svg class="w-6 h-6 text-primary-600 dark:text-primary-400" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M4.26 10.147a60.436 60.436.0 00-.491 6.347A48.627 48.627.0 0112 20.904a48.627 48.627.0 018.232-4.41 60.46 60.46.0 00-.491-6.347m-15.482.0a50.57 50.57.0 00-2.658-.813A59.905 59.905.0 0112 3.493a59.902 59.902.0 0110.399 5.84 51.39 51.39.0 00-2.658.814m-15.482.0A50.697 50.697.0 0112 13.489a50.702 50.702.0 017.74-3.342M6.75 15a.75.75.0 100-1.5.75.75.0 000 1.5m0 0v-3.675A55.378 55.378.0 0112 8.443m-7.007 11.55A5.981 5.981.0 006.75 15.75v-1.5"/></svg></div><h3 class="text-xl sm:text-2xl lg:text-3xl font-bold text-gray-900 dark:text-white tracking-tight">Education</h3></div><div class="grid grid-cols-1 md:grid-cols-2 xl:grid-cols-3 gap-6"><div class="group h-full flex flex-col bg-gradient-to-br from-white/90 to-primary-50/30 dark:from-gray-800/90 dark:to-primary-900/20 rounded-xl p-6 shadow-md hover:shadow-xl transition-all duration-300 border border-transparent hover:border-primary-200 dark:hover:border-primary-800 backdrop-blur-md"><div class="flex gap-4"><div class="flex-shrink-0 w-12 h-12 bg-primary-600 rounded-full flex items-center justify-center shadow-md"><svg class="w-6 h-6 text-white" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M4.26 10.147a60.436 60.436.0 00-.491 6.347A48.627 48.627.0 0112 20.904a48.627 48.627.0 018.232-4.41 60.46 60.46.0 00-.491-6.347m-15.482.0a50.57 50.57.0 00-2.658-.813A59.905 59.905.0 0112 3.493a59.902 59.902.0 0110.399 5.84 51.39 51.39.0 00-2.658.814m-15.482.0A50.697 50.697.0 0112 13.489a50.702 50.702.0 017.74-3.342M6.75 15a.75.75.0 100-1.5.75.75.0 000 1.5m0 0v-3.675A55.378 55.378.0 0112 8.443m-7.007 11.55A5.981 5.981.0 006.75 15.75v-1.5"/></svg></div><div class="flex-1 flex-grow"><p class="text-xl font-bold text-gray-900 dark:text-white group-hover:text-primary-600 dark:group-hover:text-primary-400 transition-colors">PhD Computer Science (NLP Focus)</p><p class="text-gray-600 dark:text-gray-400 font-medium mt-1">University of Edinburgh</p></div></div></div><div class="group h-full flex flex-col bg-gradient-to-br from-white/90 to-primary-50/30 dark:from-gray-800/90 dark:to-primary-900/20 rounded-xl p-6 shadow-md hover:shadow-xl transition-all duration-300 border border-transparent hover:border-primary-200 dark:hover:border-primary-800 backdrop-blur-md"><div class="flex gap-4"><div class="flex-shrink-0 w-12 h-12 bg-primary-600 rounded-full flex items-center justify-center shadow-md"><svg class="w-6 h-6 text-white" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M4.26 10.147a60.436 60.436.0 00-.491 6.347A48.627 48.627.0 0112 20.904a48.627 48.627.0 018.232-4.41 60.46 60.46.0 00-.491-6.347m-15.482.0a50.57 50.57.0 00-2.658-.813A59.905 59.905.0 0112 3.493a59.902 59.902.0 0110.399 5.84 51.39 51.39.0 00-2.658.814m-15.482.0A50.697 50.697.0 0112 13.489a50.702 50.702.0 017.74-3.342M6.75 15a.75.75.0 100-1.5.75.75.0 000 1.5m0 0v-3.675A55.378 55.378.0 0112 8.443m-7.007 11.55A5.981 5.981.0 006.75 15.75v-1.5"/></svg></div><div class="flex-1 flex-grow"><p class="text-xl font-bold text-gray-900 dark:text-white group-hover:text-primary-600 dark:group-hover:text-primary-400 transition-colors">MS Computer Science</p><p class="text-gray-600 dark:text-gray-400 font-medium mt-1">Dalian University of Technology</p></div></div></div><div class="group h-full flex flex-col bg-gradient-to-br from-white/90 to-primary-50/30 dark:from-gray-800/90 dark:to-primary-900/20 rounded-xl p-6 shadow-md hover:shadow-xl transition-all duration-300 border border-transparent hover:border-primary-200 dark:hover:border-primary-800 backdrop-blur-md"><div class="flex gap-4"><div class="flex-shrink-0 w-12 h-12 bg-primary-600 rounded-full flex items-center justify-center shadow-md"><svg class="w-6 h-6 text-white" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M4.26 10.147a60.436 60.436.0 00-.491 6.347A48.627 48.627.0 0112 20.904a48.627 48.627.0 018.232-4.41 60.46 60.46.0 00-.491-6.347m-15.482.0a50.57 50.57.0 00-2.658-.813A59.905 59.905.0 0112 3.493a59.902 59.902.0 0110.399 5.84 51.39 51.39.0 00-2.658.814m-15.482.0A50.697 50.697.0 0112 13.489a50.702 50.702.0 017.74-3.342M6.75 15a.75.75.0 100-1.5.75.75.0 000 1.5m0 0v-3.675A55.378 55.378.0 0112 8.443m-7.007 11.55A5.981 5.981.0 006.75 15.75v-1.5"/></svg></div><div class="flex-1 flex-grow"><p class="text-xl font-bold text-gray-900 dark:text-white group-hover:text-primary-600 dark:group-hover:text-primary-400 transition-colors">BS Computer Science</p><p class="text-gray-600 dark:text-gray-400 font-medium mt-1">Dalian University of Technology</p></div></div></div></div></div><div><div class="flex items-center gap-4 mb-8"><div class="flex-shrink-0 w-12 h-12 bg-primary-100 dark:bg-primary-900/50 rounded-full flex items-center justify-center"><svg class="w-6 h-6 text-primary-600 dark:text-primary-400" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M9.813 15.904 9 18.75l-.813-2.846a4.5 4.5.0 00-3.09-3.09L2.25 12l2.846-.813a4.5 4.5.0 003.09-3.09L9 5.25l.813 2.846a4.5 4.5.0 003.09 3.09L15.75 12l-2.846.813a4.5 4.5.0 00-3.09 3.09m8.445-7.188L18 9.75l-.259-1.035a3.375 3.375.0 00-2.455-2.456L14.25 6l1.036-.259a3.375 3.375.0 002.455-2.456L18 2.25l.259 1.035a3.375 3.375.0 002.456 2.456L21.75 6l-1.035.259a3.375 3.375.0 00-2.456 2.456m-1.365 11.852L16.5 21.75l-.394-1.183a2.25 2.25.0 00-1.423-1.423L13.5 18.75l1.183-.394a2.25 2.25.0 001.423-1.423l.394-1.183.394 1.183a2.25 2.25.0 001.423 1.423l1.183.394-1.183.394a2.25 2.25.0 00-1.423 1.423"/></svg></div><h3 class="text-xl font-bold text-gray-900 dark:text-white tracking-tight">Interests</h3></div><div class="flex flex-wrap gap-3"><span class="inline-block bg-primary-50 dark:bg-gray-800 text-primary-800 dark:text-primary-200 text-base font-medium px-4 py-2 rounded-full border border-primary-200/50 dark:border-primary-800/50
hover:bg-primary-100
dark:hover:bg-primary-500 dark:hover:text-gray-900 dark:hover:border-primary-500
transition-all duration-200 cursor-default">Multilingual NLP
</span><span class="inline-block bg-primary-50 dark:bg-gray-800 text-primary-800 dark:text-primary-200 text-base font-medium px-4 py-2 rounded-full border border-primary-200/50 dark:border-primary-800/50
hover:bg-primary-100
dark:hover:bg-primary-500 dark:hover:text-gray-900 dark:hover:border-primary-500
transition-all duration-200 cursor-default">Large Language Models
</span><span class="inline-block bg-primary-50 dark:bg-gray-800 text-primary-800 dark:text-primary-200 text-base font-medium px-4 py-2 rounded-full border border-primary-200/50 dark:border-primary-800/50
hover:bg-primary-100
dark:hover:bg-primary-500 dark:hover:text-gray-900 dark:hover:border-primary-500
transition-all duration-200 cursor-default">SFT & RLHF
</span><span class="inline-block bg-primary-50 dark:bg-gray-800 text-primary-800 dark:text-primary-200 text-base font-medium px-4 py-2 rounded-full border border-primary-200/50 dark:border-primary-800/50
hover:bg-primary-100
dark:hover:bg-primary-500 dark:hover:text-gray-900 dark:hover:border-primary-500
transition-all duration-200 cursor-default">Inference-time Intervention
</span><span class="inline-block bg-primary-50 dark:bg-gray-800 text-primary-800 dark:text-primary-200 text-base font-medium px-4 py-2 rounded-full border border-primary-200/50 dark:border-primary-800/50
hover:bg-primary-100
dark:hover:bg-primary-500 dark:hover:text-gray-900 dark:hover:border-primary-500
transition-all duration-200 cursor-default">Language Agents
</span><span class="inline-block bg-primary-50 dark:bg-gray-800 text-primary-800 dark:text-primary-200 text-base font-medium px-4 py-2 rounded-full border border-primary-200/50 dark:border-primary-800/50
hover:bg-primary-100
dark:hover:bg-primary-500 dark:hover:text-gray-900 dark:hover:border-primary-500
transition-all duration-200 cursor-default">Interpretability</span></div></div></div></div></div></div></section><section id=section-markdown class="relative hbb-section blox-markdown"><div class=home-section-bg></div><div class="flex flex-col items-center max-w-prose mx-auto gap-3 justify-center px-6"><div class="mb-6 text-3xl font-bold text-gray-900 dark:text-white">📚 My Research</div><div class="prose prose-slate lg:prose-xl dark:prose-invert max-w-prose"><p>I&rsquo;m a PhD student at the University of Edinburgh working on multilingual LLMs. My mission is to make cutting-edge NLP technology accessible across all languages, not just English.</p><p>I apply a range of qualitative and quantitative methods to comprehensively investigate the role of science and technology in the multilingual world.</p><p>Please reach out to collaborate 😃</p></div></div></section><section id=papers class="relative hbb-section blox-collection"><div class=home-section-bg></div><div class="flex flex-col items-center max-w-prose mx-auto gap-3 justify-center px-6 md:px-0"><div class="mb-6 text-3xl font-bold text-gray-900 dark:text-white">Selected Publications</div></div><div class="flex flex-col items-center px-6"><div class="container px-8 mx-auto xl:px-5 py-5 lg:py-8 max-w-screen-lg"><div class="grid gap-10 md:grid-cols-3 lg:gap-10"><div class="group bg-white/90 dark:bg-zinc-900/90 backdrop-blur-sm rounded-2xl ring-1 ring-zinc-900/5 dark:ring-white/10 shadow-lg overflow-hidden transition-all duration-300 ease-out hover:shadow-xl hover:shadow-blue-500/10 hover:-translate-y-2 focus-within:ring-2 focus-within:ring-blue-500/50" role=article aria-labelledby=card-title-527445643cd8f956c4f9a8117b5a1cde><div class="relative overflow-hidden aspect-[16/9] bg-gradient-to-br from-zinc-100 to-zinc-200 dark:from-zinc-800 dark:to-zinc-900"><a href=./publications/acl25/ class=block><img class="w-full h-full transition-transform duration-500 ease-out group-hover:scale-105 object-fill" srcset="./publications/acl25/featured_hu_c745da59e53b0697.webp 400w, ./publications/acl25/featured_hu_be95fbd8f4adc7d.webp 600w, ./publications/acl25/featured_hu_df496a36a488bc8e.webp 800w, ./publications/acl25/featured_hu_e4d3dbddaf39d6a7.webp 800w" sizes="(max-width: 768px) 100vw, (max-width: 1200px) 50vw, 33vw" src=./publications/acl25/featured_hu_c745da59e53b0697.webp width=800 height=450 loading=lazy decoding=async fetchpriority=high style=position:absolute;height:100%;width:100%;inset:0;color:transparent alt="Bridging the Language Gaps in Large Language Models with Inference-Time Cross-Lingual Intervention featured image"></a><div class="absolute inset-0 pointer-events-none bg-gradient-to-t from-black/10 via-transparent to-transparent opacity-0 group-hover:opacity-100 transition-opacity duration-300"></div></div><div class="p-8 space-y-4"><div class="flex items-center gap-2"><a href=./tags/acl25-outstanding-paper-award/><span class="inline-flex items-center px-3 py-1 rounded-full text-xs font-semibold bg-primary-100 text-primary-800 dark:bg-primary-900/40 dark:text-primary-300">ACL25 Outstanding Paper Award</span></a></div><h3 id=card-title-527445643cd8f956c4f9a8117b5a1cde class="text-xl font-bold tracking-tight text-zinc-900 dark:text-zinc-100 group-hover:text-blue-600 dark:group-hover:text-blue-400 transition-colors duration-200 leading-tight"><a href=./publications/acl25/ class=hover:underline>Bridging the Language Gaps in Large Language Models with Inference-Time Cross-Lingual Intervention</a></h3><p class="text-zinc-600 dark:text-zinc-400 text-base leading-relaxed line-clamp-3"></p><div class="flex flex-col gap-2 sm:flex-row sm:items-center justify-between pt-3 border-t border-zinc-100 dark:border-zinc-800"><div class="flex items-center gap-3 text-xs text-zinc-500 dark:text-zinc-500 flex-wrap"><div class="flex items-center gap-2 min-w-0"><div class="relative h-6 w-6 flex-shrink-0"><img alt=avatar class="rounded-full object-cover" src=./authors/admin/avatar_hu_3ec38f9caa7577a0.webp width=24 height=24 loading=lazy decoding=async></div><span class="truncate max-w-[9rem] text-sm">Weixuan Wang</span></div><span class=opacity-40>•</span>
<time class="hidden sm:inline whitespace-nowrap" datetime=2025-08-12>Aug 12, 2025
</time><span class="hidden sm:inline opacity-40">•</span>
<span class="hidden sm:inline whitespace-nowrap">1 min read</span></div><a href=./publications/acl25/ class="flex items-center gap-2 text-blue-600 dark:text-blue-400 font-medium text-sm opacity-70 group-hover:opacity-100 transform group-hover:translate-x-1 transition-all duration-300 self-start sm:self-auto sm:ml-0"><span>Read more</span>
<svg class="w-4 h-4 transition-transform group-hover:translate-x-1" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M17 8l4 4m0 0-4 4m4-4H3"/></svg></a></div></div></div><div class="group bg-white/90 dark:bg-zinc-900/90 backdrop-blur-sm rounded-2xl ring-1 ring-zinc-900/5 dark:ring-white/10 shadow-lg overflow-hidden transition-all duration-300 ease-out hover:shadow-xl hover:shadow-blue-500/10 hover:-translate-y-2 focus-within:ring-2 focus-within:ring-blue-500/50" role=article aria-labelledby=card-title-2924e11c86baf5af33716614d4e69871><div class="relative overflow-hidden aspect-[16/9] bg-gradient-to-br from-zinc-100 to-zinc-200 dark:from-zinc-800 dark:to-zinc-900"><a href=./publications/iclr25/ class=block><img class="w-full h-full transition-transform duration-500 ease-out group-hover:scale-105 object-fill" srcset="./publications/iclr25/featured_hu_7c8ea276e9f61ad2.webp 400w, ./publications/iclr25/featured_hu_5ab96a6cd970a0b9.webp 600w, ./publications/iclr25/featured_hu_74bde62fb7e65107.webp 800w, ./publications/iclr25/featured_hu_6ac48f842841e854.webp 800w" sizes="(max-width: 768px) 100vw, (max-width: 1200px) 50vw, 33vw" src=./publications/iclr25/featured_hu_7c8ea276e9f61ad2.webp width=800 height=450 loading=lazy decoding=async style=position:absolute;height:100%;width:100%;inset:0;color:transparent alt="Semantics-Adaptive Activation Intervention for LLMs via Dynamic Steering Vectors featured image"></a><div class="absolute inset-0 pointer-events-none bg-gradient-to-t from-black/10 via-transparent to-transparent opacity-0 group-hover:opacity-100 transition-opacity duration-300"></div></div><div class="p-8 space-y-4"><div class="flex items-center gap-2"><a href=./tags/iclr25/><span class="inline-flex items-center px-3 py-1 rounded-full text-xs font-semibold bg-primary-100 text-primary-800 dark:bg-primary-900/40 dark:text-primary-300">ICLR25</span></a></div><h3 id=card-title-2924e11c86baf5af33716614d4e69871 class="text-xl font-bold tracking-tight text-zinc-900 dark:text-zinc-100 group-hover:text-blue-600 dark:group-hover:text-blue-400 transition-colors duration-200 leading-tight"><a href=./publications/iclr25/ class=hover:underline>Semantics-Adaptive Activation Intervention for LLMs via Dynamic Steering Vectors</a></h3><p class="text-zinc-600 dark:text-zinc-400 text-base leading-relaxed line-clamp-3"></p><div class="flex flex-col gap-2 sm:flex-row sm:items-center justify-between pt-3 border-t border-zinc-100 dark:border-zinc-800"><div class="flex items-center gap-3 text-xs text-zinc-500 dark:text-zinc-500 flex-wrap"><div class="flex items-center gap-2 min-w-0"><div class="relative h-6 w-6 flex-shrink-0"><img alt=avatar class="rounded-full object-cover" src=./authors/admin/avatar_hu_3ec38f9caa7577a0.webp width=24 height=24 loading=lazy decoding=async></div><span class="truncate max-w-[9rem] text-sm">Weixuan Wang</span></div><span class=opacity-40>•</span>
<time class="hidden sm:inline whitespace-nowrap" datetime=2025-04-28>Apr 28, 2025
</time><span class="hidden sm:inline opacity-40">•</span>
<span class="hidden sm:inline whitespace-nowrap">1 min read</span></div><a href=./publications/iclr25/ class="flex items-center gap-2 text-blue-600 dark:text-blue-400 font-medium text-sm opacity-70 group-hover:opacity-100 transform group-hover:translate-x-1 transition-all duration-300 self-start sm:self-auto sm:ml-0"><span>Read more</span>
<svg class="w-4 h-4 transition-transform group-hover:translate-x-1" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M17 8l4 4m0 0-4 4m4-4H3"/></svg></a></div></div></div><div class="group bg-white/90 dark:bg-zinc-900/90 backdrop-blur-sm rounded-2xl ring-1 ring-zinc-900/5 dark:ring-white/10 shadow-lg overflow-hidden transition-all duration-300 ease-out hover:shadow-xl hover:shadow-blue-500/10 hover:-translate-y-2 focus-within:ring-2 focus-within:ring-blue-500/50" role=article aria-labelledby=card-title-0fb99995f74544f480050ae6eff2f4b5><div class="relative overflow-hidden aspect-[16/9] bg-gradient-to-br from-zinc-100 to-zinc-200 dark:from-zinc-800 dark:to-zinc-900"><a href=./publications/emnlp25/ class=block><img class="w-full h-full transition-transform duration-500 ease-out group-hover:scale-105 object-fill" srcset="./publications/emnlp25/featured_hu_c7658e7d61348121.webp 400w, ./publications/emnlp25/featured_hu_53ab6d81eb86e409.webp 600w, ./publications/emnlp25/featured_hu_794d0390f7e7477b.webp 800w, ./publications/emnlp25/featured_hu_f06768d003b7cee7.webp 800w" sizes="(max-width: 768px) 100vw, (max-width: 1200px) 50vw, 33vw" src=./publications/emnlp25/featured_hu_c7658e7d61348121.webp width=800 height=450 loading=lazy decoding=async style=position:absolute;height:100%;width:100%;inset:0;color:transparent alt="Demystifying Multilingual Reasoning in Process Reward Modeling featured image"></a><div class="absolute inset-0 pointer-events-none bg-gradient-to-t from-black/10 via-transparent to-transparent opacity-0 group-hover:opacity-100 transition-opacity duration-300"></div></div><div class="p-8 space-y-4"><div class="flex items-center gap-2"><a href=./tags/emnlp25-findings/><span class="inline-flex items-center px-3 py-1 rounded-full text-xs font-semibold bg-primary-100 text-primary-800 dark:bg-primary-900/40 dark:text-primary-300">EMNLP25 Findings</span></a></div><h3 id=card-title-0fb99995f74544f480050ae6eff2f4b5 class="text-xl font-bold tracking-tight text-zinc-900 dark:text-zinc-100 group-hover:text-blue-600 dark:group-hover:text-blue-400 transition-colors duration-200 leading-tight"><a href=./publications/emnlp25/ class=hover:underline>Demystifying Multilingual Reasoning in Process Reward Modeling</a></h3><p class="text-zinc-600 dark:text-zinc-400 text-base leading-relaxed line-clamp-3"></p><div class="flex flex-col gap-2 sm:flex-row sm:items-center justify-between pt-3 border-t border-zinc-100 dark:border-zinc-800"><div class="flex items-center gap-3 text-xs text-zinc-500 dark:text-zinc-500 flex-wrap"><div class="flex items-center gap-2 min-w-0"><div class="relative h-6 w-6 flex-shrink-0"><img alt=avatar class="rounded-full object-cover" src=./authors/admin/avatar_hu_3ec38f9caa7577a0.webp width=24 height=24 loading=lazy decoding=async></div><span class="truncate max-w-[9rem] text-sm">Weixuan Wang</span></div><span class=opacity-40>•</span>
<time class="hidden sm:inline whitespace-nowrap" datetime=2025-02-18>Feb 18, 2025
</time><span class="hidden sm:inline opacity-40">•</span>
<span class="hidden sm:inline whitespace-nowrap">1 min read</span></div><a href=./publications/emnlp25/ class="flex items-center gap-2 text-blue-600 dark:text-blue-400 font-medium text-sm opacity-70 group-hover:opacity-100 transform group-hover:translate-x-1 transition-all duration-300 self-start sm:self-auto sm:ml-0"><span>Read more</span>
<svg class="w-4 h-4 transition-transform group-hover:translate-x-1" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M17 8l4 4m0 0-4 4m4-4H3"/></svg></a></div></div></div><div class="group bg-white/90 dark:bg-zinc-900/90 backdrop-blur-sm rounded-2xl ring-1 ring-zinc-900/5 dark:ring-white/10 shadow-lg overflow-hidden transition-all duration-300 ease-out hover:shadow-xl hover:shadow-blue-500/10 hover:-translate-y-2 focus-within:ring-2 focus-within:ring-blue-500/50" role=article aria-labelledby=card-title-d9e011e5811b9c3abedba6a0891e7fda><div class="relative overflow-hidden aspect-[16/9] bg-gradient-to-br from-zinc-100 to-zinc-200 dark:from-zinc-800 dark:to-zinc-900"><a href=./publications/acl24/ class=block><img class="w-full h-full transition-transform duration-500 ease-out group-hover:scale-105 object-fill" srcset="./publications/acl24/featured_hu_5206339c519f53c7.webp 400w, ./publications/acl24/featured_hu_23e691d94bda6451.webp 600w, ./publications/acl24/featured_hu_1997ea646c031a43.webp 800w, ./publications/acl24/featured_hu_65609e2b00b9317b.webp 800w" sizes="(max-width: 768px) 100vw, (max-width: 1200px) 50vw, 33vw" src=./publications/acl24/featured_hu_5206339c519f53c7.webp width=800 height=450 loading=lazy decoding=async style=position:absolute;height:100%;width:100%;inset:0;color:transparent alt="Retrieval-Augmented Multilingual Knowledge Editing featured image"></a><div class="absolute inset-0 pointer-events-none bg-gradient-to-t from-black/10 via-transparent to-transparent opacity-0 group-hover:opacity-100 transition-opacity duration-300"></div></div><div class="p-8 space-y-4"><div class="flex items-center gap-2"><a href=./tags/acl24-main/><span class="inline-flex items-center px-3 py-1 rounded-full text-xs font-semibold bg-primary-100 text-primary-800 dark:bg-primary-900/40 dark:text-primary-300">ACL24 Main</span></a></div><h3 id=card-title-d9e011e5811b9c3abedba6a0891e7fda class="text-xl font-bold tracking-tight text-zinc-900 dark:text-zinc-100 group-hover:text-blue-600 dark:group-hover:text-blue-400 transition-colors duration-200 leading-tight"><a href=./publications/acl24/ class=hover:underline>Retrieval-Augmented Multilingual Knowledge Editing</a></h3><p class="text-zinc-600 dark:text-zinc-400 text-base leading-relaxed line-clamp-3"></p><div class="flex flex-col gap-2 sm:flex-row sm:items-center justify-between pt-3 border-t border-zinc-100 dark:border-zinc-800"><div class="flex items-center gap-3 text-xs text-zinc-500 dark:text-zinc-500 flex-wrap"><div class="flex items-center gap-2 min-w-0"><div class="relative h-6 w-6 flex-shrink-0"><img alt=avatar class="rounded-full object-cover" src=./authors/admin/avatar_hu_3ec38f9caa7577a0.webp width=24 height=24 loading=lazy decoding=async></div><span class="truncate max-w-[9rem] text-sm">Weixuan Wang</span></div><span class=opacity-40>•</span>
<time class="hidden sm:inline whitespace-nowrap" datetime=2024-08-02>Aug 2, 2024
</time><span class="hidden sm:inline opacity-40">•</span>
<span class="hidden sm:inline whitespace-nowrap">1 min read</span></div><a href=./publications/acl24/ class="flex items-center gap-2 text-blue-600 dark:text-blue-400 font-medium text-sm opacity-70 group-hover:opacity-100 transform group-hover:translate-x-1 transition-all duration-300 self-start sm:self-auto sm:ml-0"><span>Read more</span>
<svg class="w-4 h-4 transition-transform group-hover:translate-x-1" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M17 8l4 4m0 0-4 4m4-4H3"/></svg></a></div></div></div><div class="group bg-white/90 dark:bg-zinc-900/90 backdrop-blur-sm rounded-2xl ring-1 ring-zinc-900/5 dark:ring-white/10 shadow-lg overflow-hidden transition-all duration-300 ease-out hover:shadow-xl hover:shadow-blue-500/10 hover:-translate-y-2 focus-within:ring-2 focus-within:ring-blue-500/50" role=article aria-labelledby=card-title-fb7bbd6eaa0811de8e3d537c0c178a2e><div class="relative overflow-hidden aspect-[16/9] bg-gradient-to-br from-zinc-100 to-zinc-200 dark:from-zinc-800 dark:to-zinc-900"><a href=./publications/naacl24/ class=block><img class="w-full h-full transition-transform duration-500 ease-out group-hover:scale-105 object-fill" srcset="./publications/naacl24/featured_hu_33c6f98bc96491cb.webp 400w, ./publications/naacl24/featured_hu_67e4ff57d05d487e.webp 600w, ./publications/naacl24/featured_hu_11ae34eaa7c59e27.webp 800w, ./publications/naacl24/featured_hu_40a142498d94efa8.webp 800w" sizes="(max-width: 768px) 100vw, (max-width: 1200px) 50vw, 33vw" src=./publications/naacl24/featured_hu_33c6f98bc96491cb.webp width=800 height=450 loading=lazy decoding=async style=position:absolute;height:100%;width:100%;inset:0;color:transparent alt="Assessing the reliability of large language model knowledge featured image"></a><div class="absolute inset-0 pointer-events-none bg-gradient-to-t from-black/10 via-transparent to-transparent opacity-0 group-hover:opacity-100 transition-opacity duration-300"></div></div><div class="p-8 space-y-4"><div class="flex items-center gap-2"><a href=./tags/naacl24-oral/><span class="inline-flex items-center px-3 py-1 rounded-full text-xs font-semibold bg-primary-100 text-primary-800 dark:bg-primary-900/40 dark:text-primary-300">NAACL24 Oral</span></a></div><h3 id=card-title-fb7bbd6eaa0811de8e3d537c0c178a2e class="text-xl font-bold tracking-tight text-zinc-900 dark:text-zinc-100 group-hover:text-blue-600 dark:group-hover:text-blue-400 transition-colors duration-200 leading-tight"><a href=./publications/naacl24/ class=hover:underline>Assessing the reliability of large language model knowledge</a></h3><p class="text-zinc-600 dark:text-zinc-400 text-base leading-relaxed line-clamp-3"></p><div class="flex flex-col gap-2 sm:flex-row sm:items-center justify-between pt-3 border-t border-zinc-100 dark:border-zinc-800"><div class="flex items-center gap-3 text-xs text-zinc-500 dark:text-zinc-500 flex-wrap"><div class="flex items-center gap-2 min-w-0"><div class="relative h-6 w-6 flex-shrink-0"><img alt=avatar class="rounded-full object-cover" src=./authors/admin/avatar_hu_3ec38f9caa7577a0.webp width=24 height=24 loading=lazy decoding=async></div><span class="truncate max-w-[9rem] text-sm">Weixuan Wang</span></div><span class=opacity-40>•</span>
<time class="hidden sm:inline whitespace-nowrap" datetime=2024-06-20>Jun 20, 2024
</time><span class="hidden sm:inline opacity-40">•</span>
<span class="hidden sm:inline whitespace-nowrap">1 min read</span></div><a href=./publications/naacl24/ class="flex items-center gap-2 text-blue-600 dark:text-blue-400 font-medium text-sm opacity-70 group-hover:opacity-100 transform group-hover:translate-x-1 transition-all duration-300 self-start sm:self-auto sm:ml-0"><span>Read more</span>
<svg class="w-4 h-4 transition-transform group-hover:translate-x-1" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M17 8l4 4m0 0-4 4m4-4H3"/></svg></a></div></div></div></div></div></div></section><section id=pubs class="relative hbb-section blox-markdown"><div class=home-section-bg></div><div class="flex flex-col items-center max-w-prose mx-auto gap-3 justify-center px-6"><div class="mb-6 text-3xl font-bold text-gray-900 dark:text-white">Publications</div><div class="prose prose-slate lg:prose-xl dark:prose-invert max-w-prose"><ul><li><strong>Weixuan Wang</strong>, Minghao Wu, Barry Haddow, and Alexandra Birch (2025). <a href=https://arxiv.org/pdf/2509.20900 target=_blank rel=noopener>Learning to Summarize by Learning to Quiz: Adversarial Agentic Collaboration for Long Document Summarization</a>. <em>arXiv:22509.20900.</em></li><li><strong>Weixuan Wang</strong>, Dongge Han, Daniel Madrigal Diaz, Jin Xu, Victor Rühle, and Saravan Rajmohan (2025). <a href=https://arxiv.org/pdf/2508.09124 target=_blank rel=noopener>OdysseyBench: Evaluating LLM Agents on Long-Horizon Complex Office Application Workflows</a>. <em>arXiv:2508.09124.</em></li><li><strong>Weixuan Wang</strong>, Minghao Wu, Barry Haddow, and Alexandra Birch (2025). <a href=https://arxiv.org/pdf/2505.12300 target=_blank rel=noopener>HBO: Hierarchical Balancing Optimization for Fine-Tuning Large Language Models</a>. <em>arXiv:2505.12300.</em></li><li><strong>Weixuan Wang</strong>, Minghao Wu, Barry Haddow, and Alexandra Birch (2025). <a href=https://arxiv.org/pdf/2505.12313 target=_blank rel=noopener>ExpertSteer: Intervening in LLMs through Expert Knowledge</a>. <em>arXiv:2505.12313.</em></li><li>Minghao Wu, <strong>Weixuan Wang</strong>, Sinuo Liu, Huifeng Yin, Xintong Wang, Yu Zhao, Chenyang Lyu, Longyue Wang, Weihua Luo, and Kaifu Zhang (2025). <a href=https://arxiv.org/pdf/2504.15521 target=_blank rel=noopener>The Bitter Lesson Learned from 2,000+ Multilingual Benchmarks</a>. <em>arXiv:2504.15521.</em></li><li><strong>Weixuan Wang</strong>, Minghao Wu, Barry Haddow, and Alexandra Birch (2025). <a href=https://arxiv.org/pdf/2502.12663 target=_blank rel=noopener>Demystifying multilingual chain-of-thought in process reward modeling</a>. <em>In Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing. (EMNLP25, Findings)</em></li><li>Sherrie Shen, <strong>Weixuan Wang</strong>, and Alexandra Birch (2025). <a href=https://arxiv.org/pdf/2509.23395 target=_blank rel=noopener>Liaozhai through the Looking-Glass: On Paratextual Explicitation of Culture-Bound Terms in Machine Translation</a>. <em>In Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing.(EMNLP25, Main)</em></li><li>Yang, Jingyuan, Rongjun Li, <strong>Weixuan Wang</strong>, Ziyu Zhou, Zhiyong Feng, and Wei Peng (2025). <a href=https://arxiv.org/pdf/2501.11036 target=_blank rel=noopener>LF-Steering: Latent Feature Activation Steering for Enhancing Semantic Consistency in Large Language Models</a>. <em>arXiv:2501.11036.</em></li><li><strong>Weixuan Wang</strong>, Minghao Wu, Barry Haddow, and Alexandra Birch (2025). <a href=https://aclanthology.org/2025.acl-long.270/ target=_blank rel=noopener>Bridging the Language Gaps in Large Language Models with Inference-Time Cross-Lingual Intervention</a>. <em>In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 5418–5433. (ACL25, Oral, OutStanding Paper Award)</em></li><li><strong>Weixuan Wang</strong>, Jingyuan Yang, and Wei Peng. (2025). <a href="https://openreview.net/pdf?id=8WQ7VTfPTl" target=_blank rel=noopener>Semantics-Adaptive Activation Intervention for LLMs via Dynamic Steering Vectors</a>. <em>In The Thirteenth International Conference on Learning Representations. (ICLR25)</em></li><li><strong>Weixuan Wang</strong>, Barry Haddow, Minghao Wu, Wei Peng, and Alexandra Birch (2024). <a href=https://arxiv.org/pdf/2406.09265 target=_blank rel=noopener>Sharing Matters: Analysing Neurons Across Languages and Tasks in LLMs</a>. <em>arXiv:2406.09265.</em></li><li><strong>Weixuan Wang</strong>, Barry Haddow, and Alexandra Birch (2024). <a href=https://aclanthology.org/2024.acl-long.21/ target=_blank rel=noopener>Retrieval-Augmented Multilingual Knowledge Editing</a>. <em>In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 335–354. (ACL24, Main)</em></li><li><strong>Weixuan Wang</strong>, Barry Haddow, Alexandra Birch, and Wei Peng (2024). <a href=https://aclanthology.org/2024.naacl-long.46/ target=_blank rel=noopener>Assessing the reliability of large language model knowledge</a>. <em>In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 805–819. (NAACL24, Main, Oral)</em></li><li>Hailong Cao, Hualin Miao, <strong>Weixuan Wang</strong>, Liangyou Li, Wei Peng, and Tiejun Zhao. (2024). <a href=https://ietresearch.onlinelibrary.wiley.com/doi/pdf/10.1049/cit2.12383 target=_blank rel=noopener>Bilingual phrase induction with local hard negative sampling</a>. <em>CAAI Transactions on Intelligence Technology 10, no. 1 (2025): 147-159.</em></li><li>Hailong Cao, Tiejun Zhao, <strong>Weixuan Wang</strong>, and Wei Peng (2023). <a href=https://www.sciencedirect.com/science/article/pii/S1566253523001343 target=_blank rel=noopener>Bilingual word embedding fusion for robust unsupervised bilingual lexicon induction</a>. <em>Information Fusion, 97, 101818.</em></li><li>Hao Cheng, Meng Zhang, <strong>Weixuan Wang</strong>, Liangyou Li, Qun Liu, and Zhang, Z. (2023). <a href=https://arxiv.org/pdf/2305.02300 target=_blank rel=noopener>Evaluating the Efficacy of Length-Controllable Machine Translation</a>. <em>arXiv:2305.02300.</em></li><li><strong>Weixuan Wang</strong>, Wei Peng, and Qun Liu (2023). <a href=https://arxiv.org/pdf/2304.05860 target=_blank rel=noopener>Learning Homographic Disambiguation Representation for Neural Machine Translation</a>. <em>arXiv:2304.05860.</em></li><li><strong>Weixuan Wang</strong>, Choon Meng Lee, Jianfeng Liu, Talha Colakoglu, and Wei Peng (2023). <a href=https://www.cambridge.org/core/services/aop-cambridge-core/content/view/2485AAEE54A3870F221D5F7D98382C77/S135132492200002Xa.pdf/an-empirical-study-of-cyclical-learning-rate-on-neural-machine-translation.pdf target=_blank rel=noopener>An empirical study of cyclical learning rate on neural machine translation</a>. <em>Natural Language Engineering, 29(2), 316-336.</em></li><li><strong>Weixuan Wang</strong>, Xupeng Meng, Suqing Yan, Ye Tian, and Wei Peng (2022). <a href=https://aclanthology.org/2022.wmt-1.87.pdf target=_blank rel=noopener>Huawei BabelTar NMT at WMT22 Biomedical Translation Task: How we further improve domain-specific NMT</a>. <em>In Proceedings of the Seventh Conference on Machine Translation, pages 930-935. (WMT22)</em></li><li>Feng, Z., Hailong Cao, Tiejun Zhao, <strong>Weixuan Wang</strong>, and Wei Peng (2022). <a href=https://aclanthology.org/2022.coling-1.469.pdf target=_blank rel=noopener>Cross-lingual feature extraction from monolingual corpora for low-resource unsupervised bilingual lexicon induction</a>. <em>In Proceedings of the 29th International Conference on Computational Linguistics, pages 5278-5287. (COLING22)</em></li><li><strong>Weixuan Wang</strong>, Wei Peng, Chong Hsuan Huang, and Haoran Wang. (2022). <a href=https://arxiv.org/pdf/2208.04565 target=_blank rel=noopener>Positively transitioned sentiment dialogue corpus for developing emotion-affective open-domain chatbots</a>. <em>arXiv:2208.04565.</em></li><li><strong>Weixuan Wang</strong>, Wei Peng, Meng Zhang, and Qun Liu (2021). <a href=https://aclanthology.org/2021.emnlp-main.256.pdf target=_blank rel=noopener>Neural Machine Translation with Heterogeneous Topic Knowledge Embeddings</a>. <em>In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing pages 3197-3202). (EMNLP21, Main)</em></li><li><strong>Weixuan Wang</strong>, Wei Peng, Xupeng Meng, and Qun Liu (2021). <a href=https://aclanthology.org/2021.wmt-1.88.pdf target=_blank rel=noopener>Huawei aarc’s submissions to the wmt21 biomedical translation task: Domain adaption from a practical perspective</a>. <em>In Proceedings of the Sixth Conference on Machine Translation, pages 868-873. (WMT21)</em></li></ul></div></div></section></div><div class=page-footer><footer class="container mx-auto flex flex-col justify-items-center text-sm leading-6 mt-24 mb-4 text-slate-700 dark:text-slate-200"><p class=text-center>© 2025 Weixuan Wang.</p></footer></div><div id=hb-notification-container class="fixed top-20 right-4 z-[9999] pointer-events-none" aria-live=polite aria-atomic=true></div></body></html>